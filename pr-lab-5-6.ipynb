{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90804669",
   "metadata": {
    "papermill": {
     "duration": 0.004972,
     "end_time": "2022-09-07T16:58:36.342600",
     "exception": false,
     "start_time": "2022-09-07T16:58:36.337628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pathik Viramgama 19BCP093\n",
    "### Pattern Recognition Lab 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb039dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T16:58:36.353245Z",
     "iopub.status.busy": "2022-09-07T16:58:36.352390Z",
     "iopub.status.idle": "2022-09-07T16:58:38.071643Z",
     "shell.execute_reply": "2022-09-07T16:58:38.070239Z"
    },
    "papermill": {
     "duration": 1.728141,
     "end_time": "2022-09-07T16:58:38.074919",
     "exception": false,
     "start_time": "2022-09-07T16:58:36.346778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9646fad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T16:58:38.084733Z",
     "iopub.status.busy": "2022-09-07T16:58:38.084167Z",
     "iopub.status.idle": "2022-09-07T16:58:38.224521Z",
     "shell.execute_reply": "2022-09-07T16:58:38.222945Z"
    },
    "papermill": {
     "duration": 0.148419,
     "end_time": "2022-09-07T16:58:38.227229",
     "exception": true,
     "start_time": "2022-09-07T16:58:38.078810",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/iris/Iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2428235569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Iris(One Hot encoded?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/iris/Iris.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#Haberman\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/haberman/Haberman.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/iris/Iris.csv'"
     ]
    }
   ],
   "source": [
    "#import datasets\n",
    "#Iris(One Hot encoded?)\n",
    "df1 = pd.read_csv('../input/iris/Iris.csv')\n",
    "#Haberman\n",
    "df2 = pd.read_csv('../input/haberman/Haberman.csv')\n",
    "#AQI\n",
    "df3 = pd.read_csv('../input/air-quality-city/AQIIndia.csv')\n",
    "#Breast Cancer\n",
    "df4 = pd.read_csv('../input/breast-cancer-eda/BreastCancer.csv')\n",
    "#Red Wine\n",
    "df5 = pd.read_csv('../input/red-wine-quality-classification/RedWineQuality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a979407",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize lists to store individual features and columns as a list of list\n",
    "x_df = []\n",
    "y_df = []\n",
    "\n",
    "#datasets in one mega-list\n",
    "df = [df1, df2, df3, df4, df5]\n",
    "\n",
    "# identifiying and seperating Features and targets\n",
    "\n",
    "x_df.append(df[0].drop('Species', axis=1))\n",
    "y_df.append(df[0][['Species']])\n",
    "\n",
    "x_df.append(df[1].drop('Surv_Status', axis=1))\n",
    "y_df.append(df[1][['Surv_Status']])\n",
    "\n",
    "x_df.append(df[2].drop('AQI_Bucket', axis=1))\n",
    "y_df.append(df[2][\"AQI_Bucket\"])\n",
    "\n",
    "x_df.append(df[3].drop(\"Status\", axis=1))\n",
    "y_df.append(df[3][\"Status\"])\n",
    "\n",
    "x_df.append(df[4].drop('quality', axis=1))\n",
    "y_df.append(df[4][['quality']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1ad92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initializing train_test Lists\n",
    "xtrain_ds = []\n",
    "xtest_ds = []\n",
    "ytrain_ds = []\n",
    "ytest_ds = []\n",
    "\n",
    "# doing train_test_split for all\n",
    "for i in range(5):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_df[i], y_df[i], test_size=0.25, random_state=i)\n",
    "    xtrain_df.append(X_train)\n",
    "    xtest_df.append(X_test)\n",
    "    ytrain_df.append(y_train)\n",
    "    ytest_df.append(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a409e85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Lab 5 - Decision Tree with and without Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb1363",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiating list to store\n",
    "dts = []\n",
    "dts1 = []\n",
    "dts3 = []\n",
    "dts5 = []\n",
    "dts7 = []\n",
    "dts10 = []\n",
    "\n",
    "accuracies = [[],[],[],[],[]]\n",
    "\n",
    "#running models on each dataset for each odd depth\n",
    "for i in range(5):\n",
    "    print(\"Dataset\",i)\n",
    "    \n",
    "    # no pruning\n",
    "    dts.append(DecisionTreeClassifier(random_state=42))\n",
    "    dts[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],dts[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # pruned at 2\n",
    "    dts2.append(DecisionTreeClassifier(max_depth=2,random_state=3))\n",
    "    dts2[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],dts2[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # pruned at 3\n",
    "    dts3.append(DecisionTreeClassifier(max_depth=3,random_state=3))\n",
    "    dts3[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],dts3[i].predict(xtest_df[i])))\n",
    "    \n",
    "    #pruned at 5\n",
    "    dts5.append(DecisionTreeClassifier(max_depth=5,random_state=3))\n",
    "    dts5[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],dts5[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # pruned at 10\n",
    "    dts10.append(DecisionTreeClassifier(max_depth=10,random_state=3))\n",
    "    dts10[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "        accuracies[i].append(accuracy_score(ytest_df[i],dts0[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # pruned at 15\n",
    "    dts15.append(DecisionTreeClassifier(max_depth=15,random_state=3))\n",
    "    dts15[i].fit(xtrain_df[i],ytrain_df[i])\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],dts15[i].predict(xtest_df[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bbb3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#making columns\n",
    "pd.DataFrame(accuracies,columns=[\"Unpruned\",\"Max Depth 2\",\"Max Depth 3\",\"Max Depth 5\",\"Max Depth 10\",\"Max Depth 15\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8d69c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing max depth of tree\n",
    "dts[0].tree_.max_depth\n",
    "print(dts[1].tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540fc6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting graph for comparision\n",
    "for i in range(5):\n",
    "    plt.plot([0,2,3,5,10,15],accuracies[i][0:])\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.title(\"Dataset \"+str(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb63cc5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Lab 6 - Random Forest With and Without Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f15dab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiating Lists\n",
    "rfs = []\n",
    "rfs20 = []\n",
    "rfs50 = []\n",
    "rfs100 = []\n",
    "rfs200 = []\n",
    "rfs500 = []\n",
    "accuracies = [[],[],[],[],[]]\n",
    "\n",
    "# running model for all datasets with and without estimators\n",
    "for i in range(5):\n",
    "    print(\"Dataset\",i)\n",
    "    \n",
    "    # 10 estimators (default)\n",
    "    rfs.append(RandomForestClassifier(random_state=42))\n",
    "    rfs[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],rfs[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # 20 estimators\n",
    "    rfs20.append(RandomForestClassifier(n_estimators=20,random_state=42))\n",
    "    rfs20[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],rfs20[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # 50 estimators\n",
    "    rfs50.append(RandomForestClassifier(n_estimators=50,random_state=42))\n",
    "    rfs50[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_ds[i],rfs50[i].predict(xtest_ds[i])))\n",
    "    \n",
    "    # 100 estimators\n",
    "    rfs100.append(RandomForestClassifier(n_estimators=100,random_state=42))\n",
    "    rfs100[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],rfs100[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # 200 estimators\n",
    "    rfs200.append(RandomForestClassifier(n_estimators=200,random_state=42))\n",
    "    rfs200[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],rfs200[i].predict(xtest_df[i])))\n",
    "    \n",
    "    # 500 estimators\n",
    "    rfs500.append(RandomForestClassifier(n_estimators=500,random_state=42))\n",
    "    rfs500[i].fit(xtrain_df[i],ytrain_df[i].values.ravel())\n",
    "    accuracies[i].append(accuracy_score(ytest_df[i],rfs500[i].predict(xtest_df[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ea6c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# naming columns of accuracies\n",
    "pd.DataFrame(accuracies,columns=[\"Default(10 Trees)\",\"20 Trees\",\"50 Trees\",\"100 Trees\",\"200 Trees\",\"500 Trees\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e225ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting graph\n",
    "for i in range(5):\n",
    "    plt.plot([10,20,50,100,200,500],accuracies[i][1:])\n",
    "    plt.xlabel(\"Number of Trees\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.title(\"Dataset \"+str(i))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.136878,
   "end_time": "2022-09-07T16:58:39.056304",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-07T16:58:25.919426",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
